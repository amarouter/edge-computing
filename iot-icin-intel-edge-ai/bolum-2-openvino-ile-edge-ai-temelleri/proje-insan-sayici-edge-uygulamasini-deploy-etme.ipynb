{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İnsan sayıcı edge uygulamasını deploy ederek kazandığımız yetenekleri gösteriyoruz. Tüm OpenVINO Toolkit iş akışı üzerinden geçerek uygulamamızı tamamlıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proje Tanıtımı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu projede İnsan Sayıcı uygulama yapmak için Intel® Distribution of the OpenVINO™ Toolkit'i kullanıyoruz. Input video üzerinde inference yapma, output veriyi alma ve analiz etme, ardından veriyi sunucuya gönderme işlemlerini gerçekleştireceğiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model edge'de deploy edilecek. Inference yerel makinede yapılacak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MQTT sunucusuna aşağıdaki veriler gönderilecek:\n",
    "1. Çerçevedeki insan sayısı\n",
    "2. İnsanların çerçevede geçirdikleri süre\n",
    "3. Sayılan toplam insan sayısı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu projenin sonu için bir rapor hazırlayacağız. Bu raporda OpenVINO™ Toolkit kullanmadan önce ve kullandıktan sonra nasıl performans değişiklikleri olduğunu yazacağız. Ayrıca deploy ettiğimiz insan sayıcı uygulamanın nerelerde kullanılabileceğini de yazacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeyi tamamladığımızda OpenVINO™ Toolkit kullanarak inference için modelleri optimize etmeyi pratik yaparak deneyimlemiş olacağız. Ayrıca üretken yeteneklerimizi ve deploy ettiğimiz modelden verilerimizi alabildiğimizi de göstermiş olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sağlanan Dosyalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeye başlarken aşağıdaki üç dosya elimizde olacak:\n",
    "1. Bir MQTT sunucusu - inference yapıldıktan sonra edge uygulamamızdan gerekli bilgileri JSON olarak alır. Verileri UI sunucusuna iletir.\n",
    "2. Bir FFmpeg sunucusu - inference yapıldıktan sonra saptanan çıktıları da içeren output image frame'leri alır. Daha sonra bunları UI sunucusuna iletir.\n",
    "3. Bir UI sunucusu - kendisine gelen video girdisini, MQTT sunucusundan gelen istatistiksel bilgilerle birlikte gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üstteki dosyalar tamamen sağlandığı için ek olarak front-end veya web servisi işleri yapmamıza gerek yok. İstersek bu dosyalarda keyfi değişiklikler de yapabiliriz. Örneğin bir toggle buton ekleyerek görüntülerin iletilmesini durdurup network bandwidth'inden tasarruf sağlayabiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayrıca gerçekleştirmemizi test etmek için bir video dosyamız da sağlanacak. Ama kodumuz tek bir görüntü veya webcam akışı gibi diğer girdileri almaya da hazır olmalı."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayrıca iki dosyaya ayrılmış şekilde başlangıç kodlarımız da sağlanıyor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `inference.py` - Burada modelimizin Intermediate Representation'unu yüklüyoruz ve girdi üzerinden inference yapmak için Inference Engine ile çalışıyoruz.\n",
    "2. `main.py` - aşağıdakileri içerir:\n",
    "    - MQTT sunucuya bağlantı yapma\n",
    "    - Input stream'i işleme\n",
    "    - Inference yapmak için `inference.py`da hazırladığımız kodları kullanma\n",
    "    - Model çıktısını alma ve gerekli bilgiyi görüntüye çizme (bounding boxes, semantic masks, vs.)\n",
    "    - Görüntüdeki insan sayısını, görüntüde harcanan zamanı ve sayılan toplam insan sayısını belirlemek için output üzerinden analiz yapma\n",
    "    - İstatistikleri MQTT sunucuya yollama\n",
    "    - İşlenen görüntüyü FFmpeg sunucusuna gönderme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
